import os
import sys

# 1. å¼ºåˆ¶æ¸…ç†ä»£ç†
for key in ["http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY", "all_proxy", "ALL_PROXY"]:
    if key in os.environ:
        del os.environ[key]

# 2. é…ç½® (è¯·æ ¹æ®æ‚¨å½“å‰çš„ LM Studio æ¨¡å‹è°ƒæ•´)
os.environ["OPENAI_API_KEY"] = "lm-studio"
os.environ["OPENAI_API_BASE"] = "http://127.0.0.1:1234/v1"
os.environ["OPENAI_MODEL_NAME"] = "openai/gpt-oss-20b"

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, SystemMessage
except ImportError:
    print("âŒ ç¼ºå°‘ langchain_openai æˆ–ç›¸å…³ä¾èµ–ï¼Œè¯·å…ˆ pip install")
    sys.exit(1)

print(f"ğŸš€ [Last Verification - NoStream] è¿æ¥æœ¬åœ° LLM: {os.environ['OPENAI_API_BASE']}")
print(f"ğŸ¤– æ¨¡å‹: {os.environ['OPENAI_MODEL_NAME']}")

# 3. åˆå§‹åŒ– LLM - æœ€ç¨³å¦¥çš„éæµå¼é…ç½®
llm = ChatOpenAI(
    model=os.environ["OPENAI_MODEL_NAME"],
    openai_api_key=os.environ["OPENAI_API_KEY"],
    openai_api_base=os.environ["OPENAI_API_BASE"],
    temperature=0.7,
    streaming=False, # å…³é”®ç‚¹ï¼šå…³é—­æµå¼ï¼
    request_timeout=300, # 5åˆ†é’Ÿç»™å®ƒæ…¢æ…¢è·‘
    max_retries=1
)

# 4. å‘èµ·çº¯å¯¹è¯è¯·æ±‚
query = "What is SQL Injection? Explain in one short sentence."
print(f"\nğŸ—£ï¸ ç”¨æˆ·æŒ‡ä»¤: {query}")
print("Wait for response (Synchronous)...")

try:
    # çº¯åŒæ­¥ invoke
    response = llm.invoke([
        SystemMessage(content="You are a hacker assistant."),
        HumanMessage(content=query)
    ])
    
    print("\nğŸ“© LLM å“åº”:")
    print(f"Content: {response.content}")
    print(f"\nâœ… æˆåŠŸæ¥æ”¶ï¼")

except Exception as e:
    print(f"\nâŒ è¯·æ±‚å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print("\nâœ… éªŒè¯ç»“æŸ")
