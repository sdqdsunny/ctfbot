# v4.0 Deep Tooling & Reasoning Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Transform v3.0 into a battle-ready system with full Kali/Ghidra tool integration and a self-correcting RAG reasoning engine.

**Architecture:** Docker-based tool containers (Kali, Ghidra, Sage) accessible via MCP. A new `ReflectionNode` in the Orchestrator graph that queries a ChromaDB knowledge base upon failure.

**Tech Stack:** Docker, Ghidra, Kali Linux, ChromaDB, LangGraph, Python 3.11+.

---

## Phase A: Deep Tool Integration (The Arsenal)

### Task 1: Docker Environment (Kali & Ghidra)

**Files:**

- Create: `docker/Dockerfile.kali`
- Create: `docker/Dockerfile.ghidra`
- Modify: `docker-compose.yml`
- Test: `tests/infrastructure/test_docker_env.py`

**Step 1: Create Kali Dockerfile**

- Base: `kalilinux/kali-rolling`
- Install: `sqlmap`, `nmap`, `nuclei`, `seclists`

**Step 2: Create Ghidra Dockerfile**

- Base: `openjdk:17-slim`
- Install: Ghidra release, `unzip`

**Step 3: Update docker-compose.yml**

- Add services `kali-tooling` and `ghidra-service`

**Step 4: Verify Docker Build**

- Run: `docker-compose build`
- Expected: Success

**Step 5: Commit**
`git commit -m "infra(v4): add kali and ghidra docker environments"`

---

### Task 2: WebAgent Deep Integration

**Files:**

- Create: `src/asas_mcp/tools/kali_sqlmap.py`
- Modify: `src/asas_mcp/tools/__init__.py`
- Test: `tests/tools/test_kali_sqlmap.py`

**Step 1: Write failing test for SQLMap wrapper**

- Mock `docker exec` call to `kali-tooling` container.

**Step 2: Implement SQLMap Tool**

- Input: `url`, `params`
- Action: Execute `sqlmap --batch --dump ...` inside container.
- Output: Parse CSV or console output for flags.

**Step 3: Register Tool**

- Update `asas_mcp/tools/__init__.py`

**Step 4: Verify wrapper**
`pytest tests/tools/test_kali_sqlmap.py`

**Step 5: Commit**
`git commit -m "feat(web): implement dockerized sqlmap tool"`

---

## Phase B: Advanced Reasoning (The Brain)

### Task 3: RAG Knowledge Base

**Files:**

- Modify: `src/asas_agent/agents/memory.py`
- Create: `src/asas_agent/rag/retriever.py`
- Test: `tests/agent/test_rag.py`

**Step 1: Implement Semantic Retriever**

- Use ChromaDB to store key-value pairs (Problem Description -> Solution).

**Step 2: Update MemoryAgent**

- Add `retrieve_knowledge(query)` tool.

**Step 3: Verify Retrieval**

- Test inserting a writeup and retrieving it by semantic query.

**Step 4: Commit**
`git commit -m "feat(rag): implement semantic knowledge retrieval"`

### Task 4: Reflection Loop

**Files:**

- Modify: `src/asas_agent/graph/workflow.py`
- Modify: `src/asas_agent/graph/state.py`
- Test: `tests/agent/test_reflection.py`

**Step 1: Update AgentState**

- Add `retry_count: int` and `error_history: List[str]`.

**Step 2: Implement Reflection Node**

- Logic: If `tool_result` contains "error" and `retry_count < 3`:
  - Query Memory for similar errors.
  - Generate new plan.
  - Increment retry_count.
  - Return to `plan` node.

**Step 3: Verify Loop**

- Mock a tool failure and assert `ReflectionNode` is visited.

**Step 4: Commit**
`git commit -m "feat(reasoning): implement self-correction reflection loop"`

---

## Execution Handoff

**"Plan complete and saved to `docs/plans/2026-02-10-v4.0-implementation.md`. Two execution options:**

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task.
**2. Parallel Session (separate)** - Open new session with executing-plans.

**Which approach?"**
